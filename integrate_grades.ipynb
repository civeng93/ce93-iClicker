{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90295599-1e9b-4ac4-ac25-0e66817b438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Setup basic logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a426a591-ecbb-4083-b5d4-42a679f4c210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ‚úÖ Found 2 Canvas gradebooks and 2 iClicker files.\n",
      "INFO: Built a map of 2 official poll column names.\n",
      "INFO: Final poll columns in order: ['Class 1 - Poll (8935383)', 'Class 2 - Poll (8935377)']\n",
      "INFO: üîÑ Recalculating 'iClicker (Total) (8935426)' using all consolidated polls...\n",
      "/tmp/ipykernel_143/1867481245.py:128: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  final_df_truncated.iloc[0]=\"\"\n",
      "INFO: \n",
      "‚ú® Done! All files consolidated. Final gradebook saved to 'updated_2025-09-03T2032_Grades-CIVENG_93.csv'.\n"
     ]
    }
   ],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"A helper function to allow for natural sorting of column names like 'Class 10' after 'Class 2'.\"\"\"\n",
    "    match = re.search(r'Class (\\d+)', s)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "def run_final_grade_update():\n",
    "    \"\"\"\n",
    "    Finds and merges all Canvas and iClicker files, preserving official bCourses\n",
    "    column names and sorting them naturally before calculating the final total.\n",
    "    \"\"\"\n",
    "    for p in Path.cwd().glob('updated_*'):\n",
    "        if p.is_file(): p.unlink()\n",
    "    # --- 1. File Discovery ---\n",
    "    try:\n",
    "        all_files_in_dir = os.listdir()\n",
    "        bc_pattern = '.*_Grades-CIVENG_93.csv'\n",
    "        ic_pattern = 'iClicker_GradesExport_Canvas_.*.csv'\n",
    "\n",
    "        bc_filenames = sorted([f for f in all_files_in_dir if re.match(bc_pattern, f)], reverse=True)\n",
    "        ic_filenames = sorted([f for f in all_files_in_dir if re.match(ic_pattern, f)])\n",
    "\n",
    "        if not bc_filenames: raise StopIteration(\"No Canvas gradebook files found.\")\n",
    "\n",
    "        logging.info(f\"‚úÖ Found {len(bc_filenames)} Canvas gradebooks and {len(ic_filenames)} iClicker files.\")\n",
    "        \n",
    "    except StopIteration as e:\n",
    "        logging.error(f\"‚ùå Critical: Could not find required CSV files. {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Build a Master Map of Official Column Names ---\n",
    "    # This is crucial for keeping the bCourses format like 'Class 1 - Poll (12345)'\n",
    "    poll_column_map = {}\n",
    "    for filename in bc_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, dtype=str, nrows=0) # Read only headers for efficiency\n",
    "            for col in df.columns:\n",
    "                match = re.match(r'(Class \\d+ - Poll)( \\(\\d+\\))', col)\n",
    "                if match:\n",
    "                    simple_name = match.group(1)\n",
    "                    poll_column_map[simple_name] = col # Map 'Class 1 - Poll' -> 'Class 1 - Poll (12345)'\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not read headers from {filename}: {e}\")\n",
    "\n",
    "    logging.info(f\"Built a map of {len(poll_column_map)} official poll column names.\")\n",
    "    \n",
    "    # --- 3. Load and Prepare a Master Gradebook ---\n",
    "    try:\n",
    "        master_bc_filename = bc_filenames[0]\n",
    "        master_df = pd.read_csv(master_bc_filename, dtype=str)\n",
    "\n",
    "        # Find the official total column name from the main gradebook\n",
    "        master_total_col = next((col for col in master_df.columns if re.match(r'iClicker \\(Total\\) \\(\\d+\\)', col)), None)\n",
    "        if not master_total_col:\n",
    "            logging.error(\"‚ùå Critical: Could not find the 'iClicker (Total) (number)' column.\")\n",
    "            return\n",
    "\n",
    "        # Separate the master file into its components\n",
    "        is_student = pd.to_numeric(master_df['SIS User ID'], errors='coerce').notna()\n",
    "        student_data = master_df[is_student].copy()\n",
    "        special_rows = master_df[~is_student].copy()\n",
    "        \n",
    "        is_test_student = student_data['Student'] == 'Student, Test'\n",
    "        test_student_row = student_data[is_test_student].copy()\n",
    "        student_data = student_data[~is_test_student].copy()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred loading the main gradebook: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 4. Consolidate ALL Source Files into the Master Record ---\n",
    "    all_source_files = bc_filenames + ic_filenames\n",
    "    processed_poll_columns = set()\n",
    "\n",
    "    for filename in all_source_files:\n",
    "        try:\n",
    "            source_df = pd.read_csv(filename, dtype=str)\n",
    "            source_students = source_df[pd.to_numeric(source_df['SIS User ID'], errors='coerce').notna()].copy()\n",
    "            \n",
    "            source_poll_col_name = next((col for col in source_students.columns if 'Class' in col and 'Poll' in col), None)\n",
    "            if not source_poll_col_name: continue\n",
    "\n",
    "            simple_poll_name = re.match(r'Class \\d+ - Poll', source_poll_col_name).group(0)\n",
    "            master_poll_col_name = poll_column_map.get(simple_poll_name, simple_poll_name)\n",
    "            processed_poll_columns.add(master_poll_col_name)\n",
    "\n",
    "            if master_poll_col_name not in student_data.columns:\n",
    "                student_data[master_poll_col_name] = 0.0\n",
    "\n",
    "            source_subset = source_students[['SIS User ID', source_poll_col_name]].rename(columns={source_poll_col_name: 'New_Score'})\n",
    "            student_data = pd.merge(student_data, source_subset, on='SIS User ID', how='left')\n",
    "\n",
    "            student_data[master_poll_col_name] = pd.to_numeric(student_data[master_poll_col_name], errors='coerce').fillna(0)\n",
    "            student_data['New_Score'] = pd.to_numeric(student_data['New_Score'], errors='coerce').fillna(0)\n",
    "            student_data[master_poll_col_name] = student_data[[master_poll_col_name, 'New_Score']].max(axis=1)\n",
    "            \n",
    "            student_data.drop(columns=['New_Score'], inplace=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"  - ‚ùå An error occurred while processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # --- 5. Final Calculation and Reconstruction ---\n",
    "    # Naturally sort the poll columns before summing and saving\n",
    "    sorted_poll_columns = sorted(list(processed_poll_columns), key=natural_sort_key)\n",
    "    logging.info(f\"Final poll columns in order: {sorted_poll_columns}\")\n",
    "\n",
    "    logging.info(f\"üîÑ Recalculating '{master_total_col}' using all consolidated polls...\")\n",
    "    for col in sorted_poll_columns:\n",
    "        student_data[col] = pd.to_numeric(student_data[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    student_data[master_total_col] = student_data[sorted_poll_columns].sum(axis=1).round(2)\n",
    "    \n",
    "    final_df = pd.concat([special_rows, student_data], ignore_index=True)\n",
    "    if not test_student_row.empty:\n",
    "        final_df = pd.concat([final_df, test_student_row], ignore_index=True)\n",
    "\n",
    "    # --- 6. Save Final Truncated File ---\n",
    "    cols_to_keep = list(master_df.columns[:5]) + sorted_poll_columns + [master_total_col]\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in final_df.columns]\n",
    "    \n",
    "    final_df_truncated = final_df[cols_to_keep]\n",
    "\n",
    "    # Move student test index to the last\n",
    "    row_to_move = final_df_truncated.loc[[2]]\n",
    "    final_df_truncated = pd.concat([final_df_truncated.drop(index=2), row_to_move], ignore_index=True)\n",
    "\n",
    "    # First row to be empty\n",
    "    final_df_truncated.iloc[0]=\"\"\n",
    "    \n",
    "    \n",
    "    output_filename = f'updated_{master_bc_filename}'\n",
    "    final_df_truncated.to_csv(output_filename, encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    logging.info(f\"\\n‚ú® Done! All files consolidated. Final gradebook saved to '{output_filename}'.\")\n",
    "\n",
    "    # --- 7. Eliminate all csv files -- \n",
    "    \n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_final_grade_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8fa18-048c-4d61-a5e1-898ab7ea3000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
